{"root":{"data":{"id":"d9d52iua5dc0","created":1745322158637,"text":"集成学习算法"},"children":[{"data":{"id":"d9d52muu3c80","created":1745322167378,"text":"Bagging（Bootstrap Aggregating）"},"children":[{"data":{"id":"d9d5384eu0g0","created":1745322213669,"text":"原理"},"children":[{"data":{"id":"d9d53ednclc0","created":1745322227288,"text":"Bagging方法通过对数据集进行有放回抽样生成多个不同的训练集，然后在每个训练集上训练一个独立的基础模型，并将这些模型的结果综合起来作为最终输出。"},"children":[]}]},{"data":{"id":"d9d53iga0r40","created":1745322236155,"text":"代表算法"},"children":[{"data":{"id":"d9d53klqu880","created":1745322240839,"text":"随机森林"},"children":[{"data":{"id":"d9d53obvv7s0","created":1745322248950,"text":"一种基于决策树的bagging方法，除了对样本进行抽样外，还会在构建每棵树时对特征进行随机选择，以增加模型间的多样性。"},"children":[]}]}]},{"data":{"id":"d9d5404qm7k0","created":1745322274639,"text":"优点"},"children":[{"data":{"id":"d9d542ac3p40","created":1745322279331,"text":"减少方差，降低过拟合的风险。"},"children":[]}]},{"data":{"id":"d9d545cwlyw0","created":1745322286017,"text":"缺点"},"children":[{"data":{"id":"d9d54875p8g0","created":1745322292200,"text":"对于偏差高的基础模型效果有限。"},"children":[]}]}]},{"data":{"id":"d9d54awtcrk0","created":1745322298104,"text":"Boosting"},"children":[{"data":{"id":"d9d5384eu0g0","created":1745322213669,"text":"原理"},"children":[{"data":{"id":"d9d555uhzj40","created":1745322365445,"text":"Boosting是一种迭代方法，它按照顺序训练一系列基础模型，其中每一个新模型都会尝试纠正前面模型的错误。通常，前一个模型的误差会影响下一个模型的权重或关注点。"},"children":[]}]},{"data":{"id":"d9d53iga0r40","created":1745322236155,"text":"代表算法"},"children":[{"data":{"id":"d9d558c7pl40","created":1745322370869,"text":"AdaBoost（Adaptive Boosting）"},"children":[{"data":{"id":"d9d55acvlpc0","created":1745322375263,"text":"通过调整被错误分类实例的权重来逐步改善模型性能。"},"children":[]}]},{"data":{"id":"d9d55dtvi5s0","created":1745322382821,"text":"梯度提升（Gradient Boosting）"},"children":[{"data":{"id":"d9d55g0ojgw0","created":1745322387586,"text":"包括XGBoost、LightGBM和CatBoost等实现，通过梯度下降的方式最小化损失函数。"},"children":[]}]}]},{"data":{"id":"d9d5404qm7k0","created":1745322274639,"text":"优点"},"children":[{"data":{"id":"d9d55i0tyf40","created":1745322391949,"text":"有效减少偏差，适合处理复杂的非线性关系。"},"children":[]}]},{"data":{"id":"d9d545cwlyw0","created":1745322286017,"text":"缺点"},"children":[{"data":{"id":"d9d55jkjtrk0","created":1745322395318,"text":"可能对噪声敏感，容易过拟合。"},"children":[]}]}]},{"data":{"id":"d9d54pylx0g0","created":1745322330866,"text":"Stacking"},"children":[{"data":{"id":"d9d5384eu0g0","created":1745322213669,"text":"原理"},"children":[{"data":{"id":"d9d55m1o3n40","created":1745322400707,"text":"Stacking涉及训练多个不同类型的模型（称为第一层或基模型），然后使用另一个模型（称为元模型或第二层模型）来整合这些基模型的预测结果。"},"children":[]}]},{"data":{"id":"d9d53iga0r40","created":1745322236155,"text":"过程"},"children":[{"data":{"id":"d9d55uk0mtk0","created":1745322419230,"text":"基模型通常会采用交叉验证的方式生成预测值作为新的特征输入给元模型。"},"children":[]},{"data":{"id":"d9d55uk0o8w0","created":1745322419231,"text":"元模型负责学习如何最好地结合来自各个基模型的信息。"},"children":[]}]},{"data":{"id":"d9d5404qm7k0","created":1745322274639,"text":"优点"},"children":[{"data":{"id":"d9d55zb1dr40","created":1745322429571,"text":"能够利用不同类型模型的优势，提高预测准确性。"},"children":[]}]},{"data":{"id":"d9d545cwlyw0","created":1745322286017,"text":"缺点"},"children":[{"data":{"id":"d9d560vhfvc0","created":1745322432984,"text":"复杂度较高，可能导致过拟合；需要仔细调参。"},"children":[]}]}]},{"data":{"id":"d9d54w4ochc0","created":1745322344292,"text":"Blending"},"children":[{"data":{"id":"d9d5384eu0g0","created":1745322213669,"text":"原理"},"children":[{"data":{"id":"d9d56454e9s0","created":1745322440098,"text":"类似于Stacking，但Blending通常只用了一部分数据（如验证集）来生成基模型的预测作为元特征，而不是像Stacking那样通过交叉验证产生元特征。"},"children":[]}]},{"data":{"id":"d9d5404qm7k0","created":1745322274639,"text":"优点"},"children":[{"data":{"id":"d9d565l7v4g0","created":1745322443248,"text":"实现简单，计算成本较低。"},"children":[]}]},{"data":{"id":"d9d545cwlyw0","created":1745322286017,"text":"缺点"},"children":[{"data":{"id":"d9d567i0k9s0","created":1745322447408,"text":"可能不如Stacking灵活和强大，因为它使用的数据量较少。"},"children":[]}]}]},{"data":{"id":"d9d54ysyg0w0","created":1745322350114,"text":" Voting（投票法）"},"children":[{"data":{"id":"d9d5384eu0g0","created":1745322213669,"text":"原理"},"children":[{"data":{"id":"d9d56ac000g0","created":1745322453574,"text":"对于分类问题，Voting可以通过简单多数投票或者加权投票的方式，根据多个基础模型的预测结果决定最终分类。对于回归问题，则可能是取平均值或其他形式的聚合。"},"children":[]}]},{"data":{"id":"d9d53iga0r40","created":1745322236155,"text":"类型"},"children":[{"data":{"id":"d9d56ftb11c0","created":1745322465505,"text":"硬投票（Hard Voting）"},"children":[]},{"data":{"id":"d9d56ivwqe00","created":1745322472192,"text":"软投票（Soft Voting）"},"children":[]}]},{"data":{"id":"d9d5404qm7k0","created":1745322274639,"text":"优点"},"children":[]},{"data":{"id":"d9d545cwlyw0","created":1745322286017,"text":"缺点"},"children":[]}]}]},"template":"right","theme":"fresh-blue","version":"1.4.43"}